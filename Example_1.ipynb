{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A very simple example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I will implement the very simple example from section Subsection 3.1 of my Ideas for the Target paper. See the full details there. \n",
    "\n",
    "The general problem can be stated here.\n",
    "$$\n",
    "\\begin{gather}\n",
    "    \\nonumber \\text{Given that:} \\\\\n",
    "    \\nonumber g_0 m_0 + g_1 m_1 = d \\\\\n",
    "    \\nonumber \\text{Find} \\\\\n",
    "    \\nonumber p = t_0 m_0 + t_1 m_1 \\\\\n",
    "    \\nonumber \\text{Where:} \\\\\n",
    "    \\nonumber m_0, m_1 \\in \\mathbb{R} - \\text{Model} \\\\\n",
    "    \\nonumber g_0, g_1 \\in \\mathbb{R} - \\text{\"Sensitivity Kernel\"}\\\\\n",
    "    \\nonumber t_0, t_1 \\in \\mathbb{R} - \\text{\"Property\"} \\\\\n",
    "    \\nonumber d \\in \\mathbb{R} - \\text{Data}\n",
    "\\end{gather}\n",
    "$$\n",
    "\n",
    "For this practical example we need to give some actual values to all the variables assumed to be knwon:\n",
    "1. $g_0=1, g_1=2$ \n",
    "2. $t_0=1, t_1=1.99$\n",
    "\n",
    "Let's assume that the true model is $\\bar{m} = [10,15]^T$, therefore\n",
    "\n",
    "3. $d=40$\n",
    "4. $\\bar{p} = 39.85$ - This is the true property, what we would like to find.\n",
    "\n",
    "Without any norm bound it is obvious that our property p can take any value. So we have to introduce a norm bound $M$. The norm of the true model is $\\lVert \\bar{m} \\rVert_{\\mathcal{M}} = \\sqrt{325} \\approx 18.03$, so to emulate the fact that in reality we cannot know the true norm, we will take the norm bound to be 5 times bigger than the true norm: \n",
    "\n",
    "5. $M=5\\sqrt{325} \\approx 90.14$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step is to set up the spaces and transformations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/adrian/PhD/BGSOLA/SOLA_DLI/core')\n",
    "from core.main_classes.spaces import RN\n",
    "from core.main_classes.mappings import FiniteLinearMapping\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model space\n",
    "M = RN(dimension=2)\n",
    "# Data space\n",
    "D = RN(dimension=1)\n",
    "# Property space\n",
    "P = RN(dimension=1)\n",
    "\n",
    "# Data mapping (a row vector)\n",
    "G = FiniteLinearMapping(domain=M, \n",
    "                        codomain=D,\n",
    "                        matrix=np.array([[1, 2]]))\n",
    "# Property mapping (also a row vector)\n",
    "T = FiniteLinearMapping(domain=M, \n",
    "                        codomain=P,\n",
    "                        matrix=np.array([[1, 1.99]]))\n",
    "# Data\n",
    "data = np.array(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we find the adjoint mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_adjoint = G.adjoint()\n",
    "T_adjoint = T.adjoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general solution to the data constraint is \n",
    "$$\n",
    "\\begin{gather}\n",
    "    \\nonumber \\bar{m} \\in G^T(GG^T)^{-1}d + \\ker(G)\\\\\n",
    "    \\nonumber \\bar{m} \\in [g_0, g_1]^T \\frac{d}{g_0^2 + g_1^2} + \\ker(G)\n",
    "\\end{gather}\n",
    "$$\n",
    "where $ G^T(GG^T)^{-1}d$ is the least norm solution. We can find this solution with our mappings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pseudo-inverse mapping: \n",
      " [[0.2]\n",
      " [0.4]]\n",
      "Least norm model solution: \n",
      " [[ 8.]\n",
      " [16.]]\n"
     ]
    }
   ],
   "source": [
    "# Find pseudo-inverse\n",
    "G_pseudo_inverse = G_adjoint * (G * G_adjoint).invert()\n",
    "print('Pseudo-inverse mapping: \\n', G_pseudo_inverse.matrix)\n",
    "\n",
    "# Find least norm model solution\n",
    "m_tilde = G_pseudo_inverse.map(data)\n",
    "print('Least norm model solution: \\n', m_tilde)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the least norm model solution is not too far from the true model solution $[10,15]^T$. But we are not here for the model solution, we want to find the property bounds on $p$. For this, we need the matrix $\\mathcal{H} = T - RG$. We know $T$ and $G$, so we need to find $R$. But $R=TG^*(GG^*)^{-1}$, so it si simply $T$ composed with the G pseudo-inverse mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.996]]\n"
     ]
    }
   ],
   "source": [
    "R = T * G_pseudo_inverse\n",
    "print(R.matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can finally get "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.004 -0.002]]\n"
     ]
    }
   ],
   "source": [
    "H = T - R*G\n",
    "\n",
    "print(H.matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bgsola",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
